{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import csv\n",
    "file = './train.csv'\n",
    "\n",
    "fields = [] \n",
    "rows = [] \n",
    "  \n",
    "# reading csv file \n",
    "with open(file, 'r') as csvfile: \n",
    "    # creating a csv reader object \n",
    "    csvreader = csv.reader(csvfile) \n",
    "      \n",
    "    # extracting field names through first row \n",
    "    # fields = csvreader.next() \n",
    "  \n",
    "    # extracting each data row one by one \n",
    "    for row in csvreader: \n",
    "        rows.append(row) \n",
    "    \n",
    "rows = rows[1:]\n",
    "print(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "acids = ['A','R','N','D','C','Q','E','G','H','I','L','K','M','F','P','S','T','W','Y','V']\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for r in rows:\n",
    "    try:\n",
    "        labels.append(int(r[1]))\n",
    "        cur_seq = r[2]\n",
    "\n",
    "        cur_feature = []\n",
    "        for acid1 in acids:\n",
    "            for acid2 in acids:\n",
    "                cur_feature.append(cur_seq.count(acid1+acid2)/400*100)\n",
    "        features.append(cur_feature)\n",
    "    except:\n",
    "        print(\"error\")\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(features, labels)\n",
    "\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
    "clf = SVC(kernel='rbf',  decision_function_shape='ovo') \n",
    "\n",
    "# # from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier(n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features = 'sqrt', max_depth=70, bootstrap=False)\n",
    "\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=300)\n",
    "  \n",
    "# fitting x samples and y classes \n",
    "clf.fit(features, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = []\n",
    "\n",
    "file_test = '/kaggle/input/iqb2020/test.csv'\n",
    "\n",
    "rows_test = []\n",
    "\n",
    "\n",
    "with open(file_test, 'r') as csvfile: \n",
    "    # creating a csv reader object \n",
    "    csvreader = csv.reader(csvfile) \n",
    "      \n",
    "    # extracting field names through first row \n",
    "    # fields = csvreader.next() \n",
    "  \n",
    "    # extracting each data row one by one \n",
    "    for row in csvreader: \n",
    "        rows_test.append(row) \n",
    "    \n",
    "rows_test = rows_test[1:]\n",
    "\n",
    "ids_test = []\n",
    "for r in rows_test:\n",
    "    try:\n",
    "        ids_test.append(r[0])\n",
    "        cur_seq = r[1]\n",
    "        \n",
    "#         if (len(r[1]) > 10):\n",
    "#             cur_seq = r[1][:10]\n",
    "\n",
    "        cur_feature = []\n",
    "        for acid1 in acids:\n",
    "            for acid2 in acids:\n",
    "                cur_feature.append(cur_seq.count(acid1+acid2)/400*100)\n",
    "        features_test.append(cur_feature)\n",
    "    except:\n",
    "        print(\"error\")\n",
    "\n",
    "features_test = np.array(features_test)\n",
    "print(ids_test)\n",
    "print(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = clf.predict(features_test)\n",
    "\n",
    "fields = ['ID', 'Label']\n",
    "results = [list(a) for a in zip(ids_test, labels_test)]\n",
    "\n",
    "with open('dipeptide_svm_ovo.csv', 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile) \n",
    "      \n",
    "    # writing the fields \n",
    "    csvwriter.writerow(fields) \n",
    "      \n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
